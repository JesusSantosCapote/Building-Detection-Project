{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxFdETgvQ5RU"
      },
      "outputs": [],
      "source": [
        "!pip install awscli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymHXNz1qel--"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow tensorflow-gpu opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wXZBzdoVfB1v"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "list_building = ['airport_terminal','burial_site','park','stadium','zoo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0UzEh0yKgXEX"
      },
      "outputs": [],
      "source": [
        "for bui in list_building:\n",
        "  os.mkdir(bui)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qtvil5zie81",
        "outputId": "1bb05fc7-01d7-4b75-fd53-8d9c7fd16561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DataSet\n"
          ]
        }
      ],
      "source": [
        "%cd DataSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nu8PifckCEv"
      },
      "outputs": [],
      "source": [
        "%cd airport_terminal\n",
        "!aws s3 cp s3://spacenet-dataset/Hosted-Datasets/fmow/fmow-rgb/train/airport_terminal/ . --recursive --no-sign-request\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAAOy13nkCWM"
      },
      "outputs": [],
      "source": [
        "%cd burial_site\n",
        "!aws s3 cp s3://spacenet-dataset/Hosted-Datasets/fmow/fmow-rgb/train/burial_site/ . --recursive --no-sign-request\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWphGWIcln4Q"
      },
      "outputs": [],
      "source": [
        "%cd park\n",
        "!aws s3 cp s3://spacenet-dataset/Hosted-Datasets/fmow/fmow-rgb/train/park/ . --recursive --no-sign-request\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz0GploEln_H"
      },
      "outputs": [],
      "source": [
        "%cd stadium\n",
        "!aws s3 cp s3://spacenet-dataset/Hosted-Datasets/fmow/fmow-rgb/train/stadium/ . --recursive --no-sign-request\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gaZv90skCub"
      },
      "outputs": [],
      "source": [
        "%cd zoo\n",
        "!aws s3 cp s3://spacenet-dataset/Hosted-Datasets/fmow/fmow-rgb/train/zoo/ . --recursive --no-sign-request\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96E1Hxm4k72r",
        "outputId": "5cc57bd2-d59a-4ac1-cc60-9bd3905af018"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-4VV3jlOQqV-"
      },
      "outputs": [],
      "source": [
        "file_ = os.path.join('DataSet','airport_terminal')\n",
        "file_dest = os.path.join('NewDS','airport_terminal')\n",
        "#os.listdir(file_)\n",
        "# dir1 = os.path.join(file_,'airport_terminal_0')\n",
        "# os.listdir(dir1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUNY_0g4QqV_",
        "outputId": "538c5218-63ce-45be-8c89-796feb8408bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataSet  NewDS\tsample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "gidSXkd06Bnr"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "def portal_method(size):\n",
        "  for sub_file1 in os.listdir(file_):\n",
        "    dir1 = os.path.join(file_,sub_file1)\n",
        "    for sub_file2 in os.listdir(dir1):\n",
        "      dir2 = os.path.join(dir1,sub_file2)    \n",
        "      if os.path.splitext(dir2)[1] == '.json':\n",
        "        with open(dir2) as f:\n",
        "          try:\n",
        "            data = json.load(f)\n",
        "          except:\n",
        "            continue\n",
        "            reconstruct_from_config\n",
        "          bbox = data['bounding_boxes'][0]['box']\n",
        "          img_path = dir2[:-5]\n",
        "          im_p = img_path + '.jpg'\n",
        "          new_image = prepare_image(im_p,bbox,size,file_dest)\n",
        "          os.remove(im_p)\n",
        "          os.remove(dir2)\n",
        "\n",
        "def prepare_image(image_path, bbox, size,output_dir):\n",
        "    \"\"\"\n",
        "    Preprocesses an image for input to a CNN.\n",
        "    \n",
        "    :param image_path: Path to the input image.\n",
        "    :type image_path: str\n",
        "    :param bbox: Bounding box coordinates in the format (x_min, y_min, x_max, y_max).\n",
        "    :type bbox: tuple\n",
        "    :param size: Size of the output image in pixels.\n",
        "    :type size: int\n",
        "    :return: Preprocessed image as a numpy array.\n",
        "    \"\"\"\n",
        "    # Open the image file\n",
        "    try:\n",
        "      image = Image.open(image_path)\n",
        "    except :\n",
        "      return\n",
        "    # Enlarge the bounding box in proportion to its size\n",
        "    width, height = image.size\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    if x_min > x_max or y_min > y_max:\n",
        "      return\n",
        "    box_width = x_max - x_min\n",
        "    box_height = y_max - y_min\n",
        "    box_size = max(box_width, box_height)\n",
        "    new_x_min = max(0, x_min - box_size // 2)\n",
        "    new_y_min = max(0, y_min - box_size // 2)\n",
        "    new_x_max = min(width, x_max + box_size // 2)\n",
        "    new_y_max = min(height, y_max + box_size // 2)\n",
        "    bbox = (new_x_min, new_y_min, new_x_max, new_y_max)\n",
        "    \n",
        "    # Crop the image to the bounding box\n",
        "    image = image.crop(bbox)\n",
        "    # Resize the image for input to the CNN\n",
        "    image = image.resize((size, size))\n",
        "    # Convert the image to a numpy array\n",
        "    filename = f\"preprocessed_{os.path.basename(image_path)}\"\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    image.save(output_path)\n",
        "\n",
        "portal_method(224)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgOkxRS0dlFU"
      },
      "outputs": [],
      "source": [
        "#cuidado donde correr esto, asegurarse de estar en el directorio correcto\n",
        "for fil in os.listdir(file_):\n",
        "  dir1 = os.path.join(file_,fil)\n",
        "  print(dir1)\n",
        "  # for file in os.listdir(dir1):\n",
        "      # if os.path.splitext(os.path.join(file_dir, file))[1] == '.json':\n",
        "      #     print(os.path.splitext(os.path.join(file_dir, file))[1])\n",
        "      # if file.endswith('.jpg') or file.endswith('.json'):\n",
        "      #     os.remove(os.path.join(dir1,file))\n",
        "      #     print('delete file,',os.path.join(file_dir, file))\n",
        "  if os.path.isdir(os.path.join(file_, fil)):\n",
        "    os.rmdir(os.path.join(file_, fil))\n",
        "    print('a')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0sojnO1uABx",
        "outputId": "ae3a3249-8d91-4375-b15c-1cc91b4b80dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airport_terminal', 'stadium', 'burial_site', 'park', 'zoo']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "import os\n",
        "file_dir = 'NewDS'\n",
        "image_ext = ['jpeg','jpg','bmp','png']\n",
        "os.listdir(file_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CBMvBZ7Nu3G1"
      },
      "outputs": [],
      "source": [
        "for x in os.listdir(file_dir):\n",
        "  c = 0\n",
        "  for y in os.listdir(os.path.join(file_dir,x)):\n",
        "    if c >= 1000:\n",
        "      os.remove(os.path.join(file_dir,x,y))\n",
        "    c += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "_Hbcn7GedaAn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import imghdr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM6EAthFdlL8",
        "outputId": "beace2d0-eea1-4527-c400-674d80038dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_dir = 'NewDS'\n",
        "train_generator= datagen.flow_from_directory(train_dir,target_size=(224,224),class_mode='categorical',batch_size=32)\n",
        "num_classes = train_generator.num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSv8RsfFm4xF"
      },
      "outputs": [],
      "source": [
        "# Dividir el conjunto de datos en entrenamiento y prueba (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_generator.filenames, train_generator.classes, test_size=0.2, random_state=42)\n",
        "\n",
        "# Dividir el conjunto de entrenamiento en entrenamiento y validación (80-20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear generadores de datos para los conjuntos de entrenamiento, validación y prueba\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(224,224), class_mode='categorical', subset='training')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_generator = val_datagen.flow_from_directory(train_dir, target_size=(224,224), class_mode='categorical', subset='validation')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(train_dir, target_size=(224,224), class_mode='categorical', subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwCpGwK9n33a",
        "outputId": "766b1438-8b33-4137-b9c0-104112d4eb53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200 800 1000\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train),len(X_val),len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DYJpjD-2j6c"
      },
      "source": [
        "**Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "RkqFYcvF4Fxa"
      },
      "outputs": [],
      "source": [
        "pre = tf.keras.metrics.Precision()\n",
        "acc = tf.keras.metrics.CategoricalAccuracy()\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIggdc_RYvAf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwlE1isp2bnC",
        "outputId": "bf51c4d8-e59c-4c2b-f866-55ac1a96d766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels.h5\n",
            "242900224/242900224 [==============================] - 12s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, concatenate, Dense, Dropout, Flatten,Reshape\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.xception import Xception\n",
        "from keras import backend \n",
        "\n",
        "# Define the number of classes\n",
        "\n",
        "\n",
        "# Load DenseNet121 model\n",
        "densenet_model = DenseNet121(weights='imagenet')\n",
        "\n",
        "# Load ResNet152 model\n",
        "resnet_model = ResNet152(weights='imagenet')\n",
        "\n",
        "# # Load InceptionV3 model\n",
        "#inception_model = InceptionV3(weights='imagenet')\n",
        "\n",
        "# # Load Xception model\n",
        "#ception_model = Xception(weights= 'imagenet')\n",
        "\n",
        "# Define the input shape for all models\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Define the input tensor for all models\n",
        "input_tensor = Input(shape=input_shape)\n",
        "\n",
        "# Get the output tensors for all models\n",
        "densenet_output = densenet_model(input_tensor)\n",
        "resnet_output = resnet_model(input_tensor)\n",
        "#inception_output = inception_model(input_tensor)\n",
        "#xception_output = xception_model(input_tensor)\n",
        "\n",
        "# Concatenate the outputs of all models\n",
        "merged = concatenate([densenet_output,resnet_output])\n",
        "\n",
        "# Add a fully-connected layer with dropout and a logistic layer for the number of classes\n",
        "x = Dense(1024, activation='relu')(merged)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "\n",
        "# predicted_class = np.argmax(predictions,axis=1)\n",
        "# reshape_layer = Reshape((1,))\n",
        "# predicted_class_reshaped= reshape_layer(predicted_class)\n",
        "\n",
        "# Define the model with input tensor and output tensor\n",
        "model = Model(inputs=input_tensor, outputs=predictions)\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[acc,pre])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "gYA3RgTjGH8z"
      },
      "outputs": [],
      "source": [
        "logdir = 'logs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "s2xX-Sp-GH_G"
      },
      "outputs": [],
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mOsZvOZQqWQ",
        "outputId": "26022de5-3704-416c-e2ac-986b91a79a93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "70/70 [==============================] - 285s 1s/step - loss: 1.4599 - categorical_accuracy: 0.4317 - precision_1: 0.7119\n",
            "Epoch 2/20\n",
            "70/70 [==============================] - 77s 1s/step - loss: 1.3358 - categorical_accuracy: 0.4567 - precision_1: 0.6278\n",
            "Epoch 3/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 1.3032 - categorical_accuracy: 0.4670 - precision_1: 0.6755\n",
            "Epoch 4/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 1.1805 - categorical_accuracy: 0.4995 - precision_1: 0.7077\n",
            "Epoch 5/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 1.1476 - categorical_accuracy: 0.5217 - precision_1: 0.7120\n",
            "Epoch 6/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 1.0654 - categorical_accuracy: 0.5549 - precision_1: 0.7172\n",
            "Epoch 7/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 1.0349 - categorical_accuracy: 0.5518 - precision_1: 0.7309\n",
            "Epoch 8/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.9738 - categorical_accuracy: 0.5924 - precision_1: 0.7401\n",
            "Epoch 9/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.9476 - categorical_accuracy: 0.6170 - precision_1: 0.7601\n",
            "Epoch 10/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.9196 - categorical_accuracy: 0.6281 - precision_1: 0.7579\n",
            "Epoch 11/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.9157 - categorical_accuracy: 0.6290 - precision_1: 0.7624\n",
            "Epoch 12/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.8593 - categorical_accuracy: 0.6670 - precision_1: 0.7683\n",
            "Epoch 13/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.8402 - categorical_accuracy: 0.6844 - precision_1: 0.7572\n",
            "Epoch 14/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.8241 - categorical_accuracy: 0.6933 - precision_1: 0.7753\n",
            "Epoch 15/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.7698 - categorical_accuracy: 0.7098 - precision_1: 0.7948\n",
            "Epoch 16/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.7278 - categorical_accuracy: 0.7344 - precision_1: 0.8070\n",
            "Epoch 17/20\n",
            "70/70 [==============================] - 77s 1s/step - loss: 0.7564 - categorical_accuracy: 0.7094 - precision_1: 0.7850\n",
            "Epoch 18/20\n",
            "70/70 [==============================] - 77s 1s/step - loss: 0.7121 - categorical_accuracy: 0.7473 - precision_1: 0.8133\n",
            "Epoch 19/20\n",
            "70/70 [==============================] - 78s 1s/step - loss: 0.6413 - categorical_accuracy: 0.7728 - precision_1: 0.8245\n",
            "Epoch 20/20\n",
            "70/70 [==============================] - 77s 1s/step - loss: 0.7121 - categorical_accuracy: 0.7405 - precision_1: 0.8143\n"
          ]
        }
      ],
      "source": [
        "history_model = model.fit(train_generator,epochs=20,steps_per_epoch=70,validation_data=val_generator,callbacks=[tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TLrbGPdGIDt",
        "outputId": "3273d14f-fb97-4eb3-c80f-f557e151fc05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [1.459946870803833,\n",
              "  1.3357717990875244,\n",
              "  1.303153395652771,\n",
              "  1.1805256605148315,\n",
              "  1.1476397514343262,\n",
              "  1.0654112100601196,\n",
              "  1.0348947048187256,\n",
              "  0.9738324880599976,\n",
              "  0.9475835561752319,\n",
              "  0.9195767045021057,\n",
              "  0.9156675934791565,\n",
              "  0.8593053817749023,\n",
              "  0.8401759266853333,\n",
              "  0.8241370916366577,\n",
              "  0.7698369026184082,\n",
              "  0.7277987003326416,\n",
              "  0.7564154267311096,\n",
              "  0.712100088596344,\n",
              "  0.641268789768219,\n",
              "  0.7121441960334778],\n",
              " 'categorical_accuracy': [0.43169641494750977,\n",
              "  0.45667868852615356,\n",
              "  0.4669642746448517,\n",
              "  0.4995487332344055,\n",
              "  0.5216606259346008,\n",
              "  0.5549107193946838,\n",
              "  0.5517857074737549,\n",
              "  0.5924107432365417,\n",
              "  0.6169642806053162,\n",
              "  0.628125011920929,\n",
              "  0.6290178298950195,\n",
              "  0.666967511177063,\n",
              "  0.684374988079071,\n",
              "  0.6933035850524902,\n",
              "  0.7098214030265808,\n",
              "  0.734375,\n",
              "  0.7093862891197205,\n",
              "  0.7472923994064331,\n",
              "  0.7727678418159485,\n",
              "  0.7405234575271606],\n",
              " 'precision_1': [0.7118644118309021,\n",
              "  0.6278316974639893,\n",
              "  0.6754966974258423,\n",
              "  0.7076502442359924,\n",
              "  0.7120291590690613,\n",
              "  0.7172414064407349,\n",
              "  0.7309417128562927,\n",
              "  0.7401315569877625,\n",
              "  0.7600619196891785,\n",
              "  0.7578875422477722,\n",
              "  0.7623693346977234,\n",
              "  0.7682926654815674,\n",
              "  0.7571830749511719,\n",
              "  0.7753201127052307,\n",
              "  0.7948275804519653,\n",
              "  0.8070273399353027,\n",
              "  0.7850255370140076,\n",
              "  0.8132529854774475,\n",
              "  0.8245067596435547,\n",
              "  0.8143015503883362]}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "history_model.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5307IqOUPBxe"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate_generator(test_generator,steps=len(X_test)// 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YgvMZhLQQN7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Datos de entrenamiento\n",
        "loss = [1.2726459503173828, 1.143277883529663, 1.031258225440979]\n",
        "categorical_accuracy = [0.528124988079071,\n",
        "  0.5496389865875244,\n",
        "  0.5928571224212646]\n",
        "precision =  [0.7836644649505615, 0.6816608905792236, 0.7329721450805664]\n",
        "\n",
        "# Graficar las curvas de entrenamiento\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'b', label='Pérdida')\n",
        "plt.plot(epochs, categorical_accuracy, 'r', label='Precisión categórica')\n",
        "plt.plot(epochs, precision, 'g', label='Precisión')\n",
        "plt.title('Curvas de entrenamiento')\n",
        "plt.xlabel('Época')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySD4l3HA59Ub"
      },
      "outputs": [],
      "source": [
        "for batch in test_generator:\n",
        "  X,y = batch\n",
        "  yhat = model.predict(X)\n",
        "  pre.update_state(y,yhat)\n",
        "  acc.update_state(y,yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sg0Qi9b6QDb"
      },
      "outputs": [],
      "source": [
        "print(f'Precision:{pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4D0Z4koYl9J"
      },
      "outputs": [],
      "source": [
        "scores = model.evaluate_generator(test_generator,steps= len(X_test)//32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77k0FCLdYl_j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}